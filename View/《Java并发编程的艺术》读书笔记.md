# 并发编程的挑战

并不是启动更多的线程就能让程序最大限度第并发执行，通过多线程执行任务让程序运行更快，会遇到上下文切换、死锁、受限于硬件和软件的资源限制等问题。


单核处理器中CPU通过给每个线程分配CPU时间片来实现多线程执行任务，因为时间片非常短，一般是几十毫秒，所以CPU不停地切换线程执行，让使用者感觉是同时执行的。


CPU通过时间片分配算法来循环执行任务，切换前会保存上一个任务状态，以便下次切换回这个任务时可以再加载这个任务的状态，任务从保存到再加载的过程就是一个上下文切换，上下文切换会影响多线程的执行速度。

在数据量较小的时候，并发执行的速度并不会比串行执行慢，因为线程有创建和上下文执行的开销。



使用Lmbench可以测量上下文切换的时长，使用vmstat可以测量上下文切换的次数，每一秒切换1000多次。




|如何减少上下文切换|解释|
|----|----|
|无锁并发编程|将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。|
|CAS算法|Java的atomic包使用CAS算法来更新数据，不需要加锁。|
|使用最少线程|根据任务量创建线程，避免创建不需要的线程。如果创建太多不必要的线程，但是任务又太少，WAITTING的线程处于空闲状态，所以要减少创建的线程，这样WAITTING的线程少了，系统上下文切换的次数就会变少，因为每一次从WAITTING到RUNNABLE都会进行一次上下文的切换。|
|使用协程|在单线程里面实现多任务的调度，并在单线程里面维持多个任务间的切换。|


死锁：
线程间互相等待对方释放锁。
例如线程拿到锁后因为一些异常情况没有释放锁。
可以通过jstack来dump线程信息查看哪个线程出问题。

|避免死锁|
|----|
|避免一个线程同时获取多个锁|
|避免一个线程在锁内占用多个资源，尽量保证每个锁只占用一个资源|
|使用定时锁lock.tryLock(timeout)来替代使用内部锁机制|
|对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况|


|资源限制|解释|
|----|----|
|硬件资源限制|带宽的上传/下载速度、硬盘读写速度、CPU处理速度|
|软件资源限制|数据库的连接数、socket的连接数|


如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。

对于硬件资源限制，可以考虑使用集群并行执行程序，既然单机的资源有限制，那么就让程序在多机上执行。

对于软件资源限制，可以考虑使用资源池将资源复用。



# Java并发机制的底层实现原理

Java代码在编译后会编程Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用的并发机制，依赖于JVM的实现和CPU的指令。

|可见性|
|----|
|当一个线程修改一个变量时，另一个线程能读到这个修改的值。|

在硬件层面上Intel处理器是如何实现volatile的。

如果volatile变量修饰符使用恰当的话，比synchronized的使用和执行成本低，因为它不会引起线程上下文的切换和调度。

Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获取这个变量。Java语言提供了volatile，在某些情况下比锁更要方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。


